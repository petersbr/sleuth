% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sleuth.R
\name{sleuth_prep}
\alias{sleuth_prep}
\title{Constructor for a 'sleuth' object}
\usage{
sleuth_prep(sample_to_covariates, full_model = NULL,
  filter_fun = basic_filter, target_mapping = NULL, max_bootstrap = NULL,
  norm_fun_counts = norm_factors, norm_fun_tpm = norm_factors,
  aggregation_column = NULL, read_bootstrap_tpm = FALSE,
  extra_bootstrap_summary = FALSE, transformation_function = log_transform,
  num_cores = max(1L, parallel::detectCores() - 1L), ...)
}
\arguments{
\item{sample_to_covariates}{a \code{data.frame} which contains a mapping
from \code{sample} (a column) to some set of experimental conditions or
covariates. The column \code{path} is also required, which is a character
vector where each element points to the corresponding kallisto output directory. The column
\code{sample} should be in the same order as the corresponding entry in
\code{path}.}

\item{full_model}{an R \code{formula} which explains the full model (design)
of the experiment OR a design matrix. It must be consistent with the data.frame supplied in
\code{sample_to_covariates}. You can fit multiple covariates by joining them with '+' (see example)}

\item{filter_fun}{the function to use when filtering.}

\item{target_mapping}{a \code{data.frame} that has at least one column
'target_id' and others that denote the mapping for each target. if it is not
\code{NULL}, \code{target_mapping} is joined with many outputs where it
might be useful. For example, you might have columns 'target_id',
'ensembl_gene' and 'entrez_gene' to denote different transcript to gene
mappings.}

\item{max_bootstrap}{maximum number of bootstrap values to read for each
transcript.}

\item{norm_fun_counts}{a function to perform between sample normalization on the estimated counts.}

\item{norm_fun_tpm}{a function to perform between sample normalization on the TPM}

\item{aggregation_column}{a string of the column name in \code{\link{target_mapping}} to aggregate targets}

\item{read_bootstrap_tpm}{read and compute summary statistics on bootstraps on the TPM.
NOTE: Unnecessary for typical analyses}

\item{extra_bootstrap_summary}{if \code{TRUE}, compute extra summary
statistics needed for some plots (e.g. \code{\link{plot_bootstrap}}).
NOTE: Unnecessary for typical analyses}

\item{transformation_function}{the transformation that should be applied
to the normalized counts. Default is \code{'log(x+0.5)'} (i.e. natural log with 0.5 offset)
NOTE: be sure you know what you're doing before you change this.}

\item{num_cores}{an integer of the number of computer cores mclapply should use
to speed up sleuth preparation}

\item{...}{additional arguments passed to the filter function}
}
\value{
a \code{sleuth} object containing all kallisto samples, metadata,
and summary statistics
}
\description{
A sleuth is a group of kallistos. Borrowing this terminology, a 'sleuth' object stores
a group of kallisto results, and can then operate on them while
accounting for covariates, sequencing depth, technical and biological
variance.
}
\examples{
# Assume we have run kallisto on a set of samples, and have two treatments,
genotype and drug.
colnames(s2c)
# [1] "sample"  "genotype"  "drug"  "path"
so <- sleuth_prep(s2c, ~genotype + drug)
}
\seealso{
\code{\link{sleuth_fit}} to fit a model, \code{\link{sleuth_wt}} or
\code{\link{sleuth_lrt}} to perform hypothesis testing
}

